import torch
import torch.nn as nn
import numpy as np
from model import CharLSTM, CharRNN
from dataset import Shakespeare

def generate(model, dataset, seed_characters, temperature, length=100):
    model.eval()
    chars = [ch for ch in seed_characters]
    input_chars = [dataset.char_to_idx[ch] for ch in seed_characters]
    input_tensor = torch.tensor(input_chars).unsqueeze(0).to(next(model.parameters()).device)
    
    hidden = model.init_hidden(1)
    if isinstance(model, CharLSTM):
        hidden = (hidden[0].to(next(model.parameters()).device), hidden[1].to(next(model.parameters()).device))
    else:
        hidden = hidden.to(next(model.parameters()).device)
    
    generated_text = seed_characters
    for _ in range(length):
        output, hidden = model(input_tensor, hidden)
        output_dist = output.data.view(-1).div(max(temperature, 1e-5)).exp()
        
        # Check for NaN values and replace them
        if torch.isnan(output_dist).any():
            output_dist[torch.isnan(output_dist)] = 0

        # Normalize the distribution to prevent inf or nan values
        if output_dist.sum() == 0:
            output_dist = torch.ones_like(output_dist) / len(output_dist)
        else:
            output_dist = output_dist / output_dist.sum() + 1e-7  # 작은 값을 더해 정규화

        # Check for NaN or inf values after normalization
        if torch.isnan(output_dist).any() or torch.isinf(output_dist).any():
            print(f"NaN or inf detected in output_dist: {output_dist}")
            raise ValueError("Output distribution contains NaN or inf values")

        top_char = torch.multinomial(output_dist, 1)[0]
        
        # Clamping the index to the valid range
        top_char = torch.clamp(top_char, 0, len(dataset.idx_to_char) - 1)

        char = dataset.idx_to_char[top_char.item()]
        generated_text += char
        
        input_tensor = torch.tensor([top_char]).unsqueeze(0).to(next(model.parameters()).device)
        
    return generated_text

if __name__ == '__main__':
    input_file = 'shakespeare_train.txt'
    model_file_rnn = 'RNN_model.pth'
    model_file_lstm = 'LSTM_model.pth'
    seed_characters = "QUEEN ELIZABETH:"
    temperatures = [0.1, 1, 10]

    # Load dataset
    dataset = Shakespeare(input_file)

    # Load RNN model
    rnn_model = CharRNN(input_size=len(dataset.chars), hidden_size=128, output_size=len(dataset.chars), n_layers=2)
    rnn_model.load_state_dict(torch.load(model_file_rnn))
    rnn_model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))

    # Load LSTM model
    lstm_model = CharLSTM(input_size=len(dataset.chars), hidden_size=128, output_size=len(dataset.chars), n_layers=2)
    lstm_model.load_state_dict(torch.load(model_file_lstm))
    lstm_model.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))

    for temp in temperatures:
        print(f"Generated by RNN (T={temp})")
        try:
            generated_text_rnn = generate(rnn_model, dataset, seed_characters, temp)
            print(generated_text_rnn)
        except ValueError as e:
            print(e)
        print()

        print(f"Generated by LSTM (T={temp})")
        try:
            generated_text_lstm = generate(lstm_model, dataset, seed_characters, temp)
            print(generated_text_lstm)
        except ValueError as e:
            print(e)
        print()
